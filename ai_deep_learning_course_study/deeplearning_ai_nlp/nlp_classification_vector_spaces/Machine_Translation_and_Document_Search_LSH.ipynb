{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ca4eb8d",
   "metadata": {},
   "source": [
    "**翻译也可以看作一个向量空间的转换**\n",
    "\n",
    "例如: **XR = Y**, **X**代表英文word vector, **Y**代表法语 word vector, **R**代表映射矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd750077",
   "metadata": {},
   "source": [
    "# Vector manipulation in Python\n",
    "\n",
    "In this lab, you will have the opportunity to practice once again with the NumPy library. This time, we will explore some advanced operations with arrays and matrices.\n",
    "\n",
    "At the end of the previous module, we used PCA to transform a set of many variables into a set of only two uncorrelated variables. This process was made through a transformation of the data called rotation. \n",
    "\n",
    "In this week's assignment, you will need to find a transformation matrix from English to French vector space embeddings. Such a transformation matrix is nothing else but a matrix that rotates and scales vector spaces.\n",
    "\n",
    "In this notebook, we will explain in detail the rotation transformation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b330432",
   "metadata": {},
   "source": [
    "## Transforming vectors\n",
    "\n",
    "There are three main vector transformations:\n",
    "* Scaling\n",
    "* Translation\n",
    "* Rotation\n",
    "\n",
    "In previous notebooks, we have applied the first two kinds of transformations. Now, let us learn how to use a fundamental transformation on vectors called _rotation_.\n",
    "\n",
    "The rotation operation changes the direction of a vector, letting unaffected its dimensionality and its norm. Let us explain with some examples. \n",
    "\n",
    "In the following cells, we will define a NumPy matrix and a NumPy array. Soon we will explain how this is related to matrix rotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6de333f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "344ef197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vectors(vectors, colors=['k', 'b', 'r', 'm', 'c'], axes=None, fname='image.svg', ax=None):\n",
    "    \"\"\"Procedure to plot and arrows that represents vectors with pyplot\"\"\"\n",
    "    scale = 1\n",
    "    scale_units = 'x'\n",
    "    x_dir = []\n",
    "    y_dir = []\n",
    "    \n",
    "    for i, vec in enumerate(vectors):\n",
    "        x_dir.append(vec[0][0])\n",
    "        y_dir.append(vec[0][1])\n",
    "    \n",
    "    if ax == None:\n",
    "        fig, ax2 = plt.subplots()\n",
    "    else:\n",
    "        ax2 = ax\n",
    "      \n",
    "    if axes == None:\n",
    "        x_axis = 2 + np.max(np.abs(x_dir))\n",
    "        y_axis = 2 + np.max(np.abs(y_dir))\n",
    "    else:\n",
    "        x_axis = axes[0]\n",
    "        y_axis = axes[1]\n",
    "        \n",
    "    ax2.axis([-x_axis, x_axis, -y_axis, y_axis])\n",
    "        \n",
    "    for i, vec in enumerate(vectors):\n",
    "        ax2.arrow(0, 0, vec[0][0], vec[0][1], head_width=0.05 * x_axis, head_length=0.05 * y_axis, fc=colors[i], ec=colors[i])\n",
    "    \n",
    "    if ax == None:\n",
    "        plt.show()\n",
    "        fig.savefig(fname)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ae1153",
   "metadata": {},
   "source": [
    "## Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5040d779",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.array([[2, 0], [0, -2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eecd49c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([[1, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709ca8ab",
   "metadata": {},
   "source": [
    "The dot product between a vector and a square matrix produces a rotation and a scaling of the original vector. \n",
    "\n",
    "Remember that our recommended way to get the dot product in Python is np.dot(a, b):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4933c7f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2, -2]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=np.dot(x, R)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd74a4f",
   "metadata": {},
   "source": [
    "We are going to use Pyplot to inspect the effect of the rotation on 2D vectors visually. For that, we have created a function `plot_vectors()` that takes care of all the intricate parts of the visual formatting. The code for this function is inside the `utils_nb.py` file. \n",
    "\n",
    "Now we can plot the vector $\\vec x = [1, 1]$ in a cartesian plane. The cartesian plane will be centered at `[0,0]` and its x and y limits will be between `[-4, +4]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e93f392d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_vectors([x], axes=[4, 4], fname='transform_x.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e68951",
   "metadata": {},
   "source": [
    "Now, let's plot in the same system our vector $\\vec x = [1, 1]$ and its dot product with the matrix\n",
    "\n",
    "$$Ro = \\begin{bmatrix} 2 & 0 \\\\ 0 & -2 \\end{bmatrix}$$\n",
    "\n",
    "$$y = x \\cdot Ro = [[-2, 2]]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "553e8a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_vectors([x, y], axes=[4, 4], fname='transformx_and_y.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2161cbe8",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "\n",
    "We are going to use Pyplot to inspect the effect of the rotation on 2D vectors visually. For that, we have created a function that takes care of all the intricate parts of the visual formatting. The following procedure plots an arrow within a Pyplot canvas.\n",
    "\n",
    "Data that is composed of 2 real attributes is telling to belong to a $ RxR $ or $ R^2 $ space. Rotation matrices in $R^2$ rotate a given vector $\\vec x$ by a counterclockwise angle $\\theta$ in a fixed coordinate system. Rotation matrices are of the form:\n",
    "\n",
    "$$Ro = \\begin{bmatrix} cos \\theta & -sin \\theta \\\\ sin \\theta & cos \\theta \\end{bmatrix}$$\n",
    "\n",
    "The trigonometric functions in Numpy require the angle in radians, not in degrees. In the next cell, we define a rotation matrix that rotates vectors by $45^o$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c23d5134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotation matrix\n",
      "[[-0.17364818 -0.98480775]\n",
      " [ 0.98480775 -0.17364818]]\n",
      "\n",
      "Rotated vector\n",
      "[[ 1.62231915 -2.31691186]]\n",
      "\n",
      " x2 norm 2.8284271247461903\n",
      "\n",
      " y2 norm 2.82842712474619\n",
      "\n",
      " Rotation matrix norm 1.414213562373095\n"
     ]
    }
   ],
   "source": [
    "angle = 100 * (np.pi / 180)  # convert degrees to radians\n",
    "\n",
    "Ro = np.array([[np.cos(angle), -np.sin(angle)],\n",
    "              [np.sin(angle), np.cos(angle)]])\n",
    "\n",
    "x2 = np.array([2, 2]).reshape(1, -1)  # make it a row vector\n",
    "y2 = np.dot(x2, Ro)\n",
    "\n",
    "print('Rotation matrix')\n",
    "print(Ro)\n",
    "print('\\nRotated vector')\n",
    "print(y2)\n",
    "\n",
    "print('\\n x2 norm', np.linalg.norm(x2))\n",
    "print('\\n y2 norm', np.linalg.norm(y2))\n",
    "print('\\n Rotation matrix norm', np.linalg.norm(Ro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24666a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_vectors([x2, y2], fname='transform_02.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80569d2e",
   "metadata": {},
   "source": [
    "Some points to note:\n",
    "\n",
    "* The norm of the input vector is the same as the norm of the output vector. Rotations matrices do not modify the norm of the vector, only its direction.\n",
    "* The norm of any $R^2$ rotation matrix is always $\\sqrt 2 = 1.414221$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d247df5",
   "metadata": {},
   "source": [
    "## Frobenius Norm\n",
    "\n",
    "The Frobenius norm is the generalization to $R^2$ of the already known norm function for vectors \n",
    "\n",
    "$$\\| \\vec a \\| = \\sqrt {{\\vec a} \\cdot {\\vec a}} $$\n",
    "\n",
    "For a given $R^2$ matrix A, the frobenius norm is defined as:\n",
    "\n",
    "$$\\|\\mathrm{A}\\|_{F} \\equiv \\sqrt{\\sum_{i=1}^{m} \\sum_{j=1}^{n}\\left|a_{i j}\\right|^{2}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97aa57e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[2, 2],\n",
    "              [2, 2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf869559",
   "metadata": {},
   "source": [
    "`np.square()` is a way to square each element of a matrix. It must be equivalent to use the * operator in Numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ba37776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 4],\n",
       "       [4, 4]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_squared = np.square(A)\n",
    "A_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9b3cfd",
   "metadata": {},
   "source": [
    "Now you can sum over the elements of the resulting array, and then get the square root of the sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf3dc7e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_Frobenius = np.sqrt(np.sum(A_squared))\n",
    "A_Frobenius"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449c122e",
   "metadata": {},
   "source": [
    "That was the extended version of the `np.linalg.norm()` function. You can check that it yields the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29e1f179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frobenius norm of the Rotation matrix\n",
      "1.414213562373095 ==  1.414213562373095\n"
     ]
    }
   ],
   "source": [
    "print('Frobenius norm of the Rotation matrix')\n",
    "print(np.sqrt(np.sum(Ro * Ro)), '== ', np.linalg.norm(Ro))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfa3fa3",
   "metadata": {},
   "source": [
    "**Congratulations!! We've covered a few more matrix operations in this lab. This will come in handy in this week's programming assignment!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5236e3c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55edab0e",
   "metadata": {},
   "source": [
    "# Hash functions and multiplanes\n",
    "\n",
    "\n",
    "In this lab, we are going to practice the most important concepts related to the hash functions explained in the videos. You will be using these in this week's assignment.\n",
    "\n",
    "A key point for the lookup using hash functions is the calculation of the hash key or bucket id that we assign for a given entry. In this notebook, we will cover:\n",
    "\n",
    "* Basic hash tables\n",
    "* Multiplanes\n",
    "* Random planes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3b7b66",
   "metadata": {},
   "source": [
    "## Basic Hash tables\n",
    "\n",
    "Hash tables are data structures that allow indexing data to make lookup tasks more efficient. \n",
    "In this part, you will see the implementation of the simplest hash function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f237a979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0022a87",
   "metadata": {},
   "source": [
    "In the next cell, we will define a straightforward hash function for integer numbers. The function will receive a list of integer numbers and the desired amount of buckets. The function will produce a hash table stored as a dictionary, where keys contain the hash keys, and the values will provide the hashed elements of the input list. \n",
    "\n",
    "The hash function is just the remainder of the integer division between each element and the desired number of buckets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4916f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_hash_table(value_1, n_buckets):\n",
    "    def hash_function(value, n_buckets):\n",
    "        return int(value) % n_buckets\n",
    "    \n",
    "    hash_table = {i:[] for i in range(n_buckets)}\n",
    "    \n",
    "    for value in values_1:\n",
    "        hash_value = hash_function(value, n_buckets)\n",
    "        hash_table[hash_value].append(value)\n",
    "        \n",
    "    return hash_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e009ec1d",
   "metadata": {},
   "source": [
    "Now let's see the hash table function in action. The pretty print function (`pprint()`) will produce a visually appealing output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7cbbed21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   0: [100, 10],\n",
      "    1: [],\n",
      "    2: [],\n",
      "    3: [],\n",
      "    4: [14],\n",
      "    5: [],\n",
      "    6: [],\n",
      "    7: [17, 97],\n",
      "    8: [],\n",
      "    9: []}\n"
     ]
    }
   ],
   "source": [
    "values_1 = [100,10,14,17,97]\n",
    "hash_table_ex = basic_hash_table(values_1, n_buckets=10)\n",
    "pp.pprint(hash_table_ex)\n",
    "# hash_table_ex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9690db",
   "metadata": {},
   "source": [
    "In this case, the bucket key must be the rightmost digit of each number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b7b608",
   "metadata": {},
   "source": [
    "## Planes\n",
    "\n",
    "Multiplanes hash functions are other types of hash functions. Multiplanes hash functions are based on the idea of numbering every single region that is formed by the intersection of n planes. In the following code, we show the most basic forms of the multiplanes principle. First, with a single plane:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d79f1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_vectors(vectors, colors=['k', 'b', 'r', 'm', 'c'], axes=None, fname='image.svg', ax=None):\n",
    "    scale = 1\n",
    "    scale_units = 'x'\n",
    "    x_dir = []\n",
    "    y_dir = []\n",
    "    \n",
    "    for i, vec in enumerate(vectors):\n",
    "        x_dir.append(vec[0][0])\n",
    "        y_dir.append(vec[0][1])\n",
    "    \n",
    "    if ax == None:\n",
    "        fig, ax2 = plt.subplots()\n",
    "    else:\n",
    "        ax2 = ax\n",
    "      \n",
    "    if axes == None:\n",
    "        x_axis = 2 + np.max(np.abs(x_dir))\n",
    "        y_axis = 2 + np.max(np.abs(y_dir))\n",
    "    else:\n",
    "        x_axis = axes[0]\n",
    "        y_axis = axes[1]\n",
    "        \n",
    "    ax2.axis([-x_axis, x_axis, -y_axis, y_axis])\n",
    "        \n",
    "    for i, vec in enumerate(vectors):\n",
    "        ax2.arrow(0, 0, vec[0][0], vec[0][1], head_width=0.05 * x_axis, head_length=0.05 * y_axis, fc=colors[i], ec=colors[i])\n",
    "    \n",
    "    if ax == None:\n",
    "        plt.show()\n",
    "        fig.savefig(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80615410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "P = np.array([[1, 1]]) # Define a single plane. \n",
    "fig, ax1 = plt.subplots(figsize=(8, 8)) # Create a plot\n",
    "\n",
    "plot_vectors([P], axes=[2, 2], ax=ax1) # Plot the plane P as a vector\n",
    "\n",
    "# Plot  random points. \n",
    "for i in range(0, 10):\n",
    "        v1 = np.array(np.random.uniform(-2, 2, 2)) # Get a pair of random numbers between -4 and 4 \n",
    "        side_of_plane = np.sign(np.dot(P, v1.T)) \n",
    "        \n",
    "        # Color the points depending on the sign of the result of np.dot(P, point.T)\n",
    "        if side_of_plane == 1:\n",
    "            ax1.plot([v1[0]], [v1[1]], 'bo') # Plot blue points\n",
    "        else:\n",
    "            ax1.plot([v1[0]], [v1[1]], 'ro') # Plot red points\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9897a191",
   "metadata": {},
   "source": [
    "The first thing to note is that the vector that defines the plane does not mark the boundary between the two sides of the plane. It marks the direction in which you find the 'positive' side of the plane. Not intuitive at all!\n",
    "\n",
    "If we want to plot the separation plane, we need to plot a line that is perpendicular to our vector `P`. We can get such a line using a $90^o$ rotation matrix.\n",
    "\n",
    "Feel free to change the direction of the plane `P`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e9bc4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "P = np.array([[1, 2]])  # Define a single plane. You may change the direction\n",
    "\n",
    "# Get a new plane perpendicular to P. We use a rotation matrix\n",
    "PT = np.dot([[0, 1], [-1, 0]], P.T).T  \n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(8, 8)) # Create a plot with custom size\n",
    "\n",
    "plot_vectors([P], colors=['b'], axes=[2, 2], ax=ax1) # Plot the plane P as a vector\n",
    "\n",
    "# Plot the plane P as a 2 vectors. \n",
    "# We scale by 2 just to get the arrows outside the current box\n",
    "plot_vectors([PT * 4, PT * -4], colors=['k', 'k'], axes=[4, 4], ax=ax1)\n",
    "\n",
    "# Plot 20 random points. \n",
    "for i in range(0, 20):\n",
    "    v1 = np.array(np.random.uniform(-4, 4, 2)) # Get a pair of random numbers between -4 and 4 \n",
    "    side_of_plane = np.sign(np.dot(P, v1.T)) # Get the sign of the dot product with P\n",
    "    # Color the points depending on the sign of the result of np.dot(P, point.T)\n",
    "    if side_of_plane == 1:\n",
    "        ax1.plot([v1[0]], [v1[1]], 'bo') # Plot a blue point\n",
    "    else:\n",
    "        ax1.plot([v1[0]], [v1[1]], 'ro') # Plot a red point\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16160466",
   "metadata": {},
   "source": [
    "Now, let us see what is inside the code that color the points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e143ee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.array([[1, 1]])      # Single plane\n",
    "v1 = np.array([[1, 2]])     # Sample point 1\n",
    "v2 = np.array([[-1, 1]])    # Sample point 2\n",
    "v3 = np.array([[-2, -1]])   # Sample point 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "40f403bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(P, v1.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae7f5740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(P, v2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f462dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(P, v3.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddedfaaf",
   "metadata": {},
   "source": [
    "The function below checks in which side of the plane P is located the vector `v`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f060cbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def side_of_plane(P, v):\n",
    "    dot = np.dot(P, v.T)\n",
    "    sign_of_dot = np.sign(dot)\n",
    "    sign_of_dot_scalar = sign_of_dot.item()\n",
    "    return sign_of_dot_scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "555584b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "side_of_plane(P, v1) # In which side is [1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9c8a4298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "side_of_plane(P, v2) # In which side is [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1351af17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "side_of_plane(P, v3) # In which side is [-2, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e4d05c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sign(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b47ecd",
   "metadata": {},
   "source": [
    "## Hash Function with multiple planes\n",
    "\n",
    "In the following section, we are going to define a hash function with a list of three custom planes in 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b068eba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[1, 1]]), array([[-1,  1]]), array([[-1, -1]])]\n",
      "array([[2, 2]])\n"
     ]
    }
   ],
   "source": [
    "P1 = np.array([[1, 1]])   # First plane 2D\n",
    "P2 = np.array([[-1, 1]])  # Second plane 2D\n",
    "P3 = np.array([[-1, -1]]) # Third plane 2D\n",
    "P_l = [P1, P2, P3]  # List of arrays. It is the multi plane\n",
    "\n",
    "pp.pprint(P_l)\n",
    "\n",
    "# Vector to search\n",
    "v = np.array([[2, 2]])\n",
    "\n",
    "pp.pprint(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e515ff6b",
   "metadata": {},
   "source": [
    "The next function creates a hash value based on a set of planes. The output value is a combination of the side of the plane where the vector is localized with respect to the collection of planes.\n",
    "\n",
    "We can think of this list of planes as a set of basic hash functions, each of which can produce only 1 or 0 as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "80da34fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_multi_plane(P_l, v):\n",
    "    \"\"\"hash_value = 求和 2^i * h_i\"\"\"\n",
    "    hash_value = 0\n",
    "    for i, P in enumerate(P_l):\n",
    "        sign = side_of_plane(P,v)\n",
    "        hash_i = 1 if sign >=0 else 0\n",
    "        hash_value += 2**i * hash_i\n",
    "        \n",
    "    return hash_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "43311502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash_multi_plane(P_l, v) # Find the number of the plane that containes this value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c115ae",
   "metadata": {},
   "source": [
    "## Random Planes\n",
    "\n",
    "In the cell below, we create a set of three random planes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1b136551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.76405235  0.40015721]\n",
      " [ 0.97873798  2.2408932 ]\n",
      " [ 1.86755799 -0.97727788]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "num_dimensions = 2 # is 300 in assignment\n",
    "num_planes = 3 # is 10 in assignment\n",
    "random_planes_matrix = np.random.normal(\n",
    "                       size=(num_planes,\n",
    "                             num_dimensions))\n",
    "print(random_planes_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "62b0ee9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.array([[2, 2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ab7ecf",
   "metadata": {},
   "source": [
    "The next function is similar to the `side_of_plane()` function, but it evaluates more than a plane each time. The result is an array with the side of the plane of `v`, for the set of planes `P`# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1a0ac9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def side_of_plane_matrix(P,v):\n",
    "    dot=np.dot(P,v.T)\n",
    "    sign_of_dot=np.sign(dot)\n",
    "    return sign_of_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b0ea32",
   "metadata": {},
   "source": [
    "Get the side of the plane of the vector `[2, 2]` for the set of random planes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1a4c3694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "side_1 = side_of_plane_matrix(random_planes_matrix,v)\n",
    "\n",
    "side_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be7c44a",
   "metadata": {},
   "source": [
    "Now, let us use the former function to define our multiplane hash function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7a0b0bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_multi_plane_matrix(P,v,num_planes):\n",
    "    \n",
    "    # Get the side of planes for P and v\n",
    "    sizes_matrix=side_of_plane_matrix(P,v)\n",
    "    \n",
    "    hash_value=0\n",
    "    \n",
    "    for i in range(num_planes):\n",
    "        sign=sizes_matrix[i].item()\n",
    "        hash_i=1 if sign >=0 else 0\n",
    "        hash_value+=2**i*hash_i\n",
    "        \n",
    "    return hash_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2bcc49",
   "metadata": {},
   "source": [
    "Print the bucket hash for the vector `v = [2, 2]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0e22dd93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash_multi_plane_matrix(random_planes_matrix, v, num_planes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652a08ba",
   "metadata": {},
   "source": [
    "#### Note\n",
    "This showed you how to make one set of random planes.  You will make multiple sets of random planes in order to make the approximate nearest neighbors more accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22c4bd4",
   "metadata": {},
   "source": [
    "## Document vectors\n",
    "\n",
    "Before we finish this lab, remember that you can represent a document as a vector by adding up the word vectors for the words inside the document. In this example, our embedding contains only three words, each represented by a 3D array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b44babc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 3]\n"
     ]
    }
   ],
   "source": [
    "word_embedding = {\"I\": np.array([1,0,1]),\n",
    "                   \"love\": np.array([-1,0,1]),\n",
    "                   \"learning\": np.array([1,0,1])\n",
    "                  }\n",
    "words_in_document = ['I', 'love', 'learning', 'not_a_word']\n",
    "document_embedding = np.array([0,0,0])\n",
    "for word in words_in_document:\n",
    "    document_embedding += word_embedding.get(word,0)\n",
    "    \n",
    "print(document_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fbace3",
   "metadata": {},
   "source": [
    "**Congratulations! You've now completed this lab on hash functions and multiplanes!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ab7ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a6005c7",
   "metadata": {},
   "source": [
    "# Assignment 4 - Naive Machine Translation and LSH\n",
    "\n",
    "You will now implement your first machine translation system and then you\n",
    "will see how locality sensitive hashing works. Let's get started by importing\n",
    "the required functions!\n",
    "\n",
    "If you are running this notebook in your local computer, don't forget to\n",
    "download the twitter samples and stopwords from nltk.\n",
    "\n",
    "```\n",
    "nltk.download('stopwords')\n",
    "nltk.download('twitter_samples')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "95b10e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import pickle\n",
    "import string\n",
    "import time\n",
    "import gensim\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import scipy\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.corpus import stopwords,twitter_samples\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "from os import getcwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0040eef",
   "metadata": {},
   "source": [
    "# 1. The word embeddings data for English and French words\n",
    "\n",
    "Write a program that translates English to French.\n",
    "\n",
    "## The data\n",
    "\n",
    "The full dataset for English embeddings is about 3.64 gigabytes, and the French\n",
    "embeddings are about 629 megabytes. To prevent the Coursera workspace from\n",
    "crashing, we've extracted a subset of the embeddings for the words that you'll\n",
    "use in this assignment.\n",
    "\n",
    "If you want to run this on your local computer and use the full dataset,\n",
    "you can download the\n",
    "* English embeddings from Google code archive word2vec\n",
    "[look for GoogleNews-vectors-negative300.bin.gz](https://code.google.com/archive/p/word2vec/)\n",
    "    * You'll need to unzip the file first.\n",
    "* and the French embeddings from\n",
    "[cross_lingual_text_classification](https://github.com/vjstark/crosslingual_text_classification).\n",
    "    * in the terminal, type (in one line)\n",
    "    `curl -o ./wiki.multi.fr.vec https://dl.fbaipublicfiles.com/arrival/vectors/wiki.multi.fr.vec`\n",
    "\n",
    "Then copy-paste the code below and run it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301c68b0",
   "metadata": {},
   "source": [
    "```python\n",
    "# Use this code to download and process the full dataset on your local computer\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "en_embeddings = KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary = True)\n",
    "fr_embeddings = KeyedVectors.load_word2vec_format('./wiki.multi.fr.vec')\n",
    "\n",
    "\n",
    "# loading the english to french dictionaries\n",
    "en_fr_train = get_dict('en-fr.train.txt')\n",
    "print('The length of the english to french training dictionary is', len(en_fr_train))\n",
    "en_fr_test = get_dict('en-fr.test.txt')\n",
    "print('The length of the english to french test dictionary is', len(en_fr_train))\n",
    "\n",
    "english_set = set(en_embeddings.vocab)\n",
    "french_set = set(fr_embeddings.vocab)\n",
    "en_embeddings_subset = {}\n",
    "fr_embeddings_subset = {}\n",
    "french_words = set(en_fr_train.values())\n",
    "\n",
    "for en_word in en_fr_train.keys():\n",
    "    fr_word = en_fr_train[en_word]\n",
    "    if fr_word in french_set and en_word in english_set:\n",
    "        en_embeddings_subset[en_word] = en_embeddings[en_word]\n",
    "        fr_embeddings_subset[fr_word] = fr_embeddings[fr_word]\n",
    "\n",
    "\n",
    "for en_word in en_fr_test.keys():\n",
    "    fr_word = en_fr_test[en_word]\n",
    "    if fr_word in french_set and en_word in english_set:\n",
    "        en_embeddings_subset[en_word] = en_embeddings[en_word]\n",
    "        fr_embeddings_subset[fr_word] = fr_embeddings[fr_word]\n",
    "\n",
    "\n",
    "pickle.dump( en_embeddings_subset, open( \"en_embeddings.p\", \"wb\" ) )\n",
    "pickle.dump( fr_embeddings_subset, open( \"fr_embeddings.p\", \"wb\" ) )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1158ebbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_embeddings_subset = pickle.load(open(\"en_embeddings.p\",\"rb\"))\n",
    "fr_embeddings_subset = pickle.load(open(\"fr_embeddings.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4378ce83",
   "metadata": {},
   "source": [
    "#### Look at the data\n",
    "\n",
    "* en_embeddings_subset: the key is an English word, and the vaule is a\n",
    "300 dimensional array, which is the embedding for that word.\n",
    "```\n",
    "'the': array([ 0.08007812,  0.10498047,  0.04980469,  0.0534668 , -0.06738281, ....\n",
    "```\n",
    "\n",
    "* fr_embeddings_subset: the key is an French word, and the vaule is a 300\n",
    "dimensional array, which is the embedding for that word.\n",
    "```\n",
    "'la': array([-6.18250e-03, -9.43867e-04, -8.82648e-03,  3.24623e-02,...\n",
    "```\n",
    "\n",
    "#### Load two dictionaries mapping the English to French words\n",
    "* A training dictionary\n",
    "* and a testing dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d612f753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict(file_name):\n",
    "    my_file = pd.read_csv(file_name, delimiter=' ')\n",
    "    \n",
    "    etof={}\n",
    "    \n",
    "    for i in range(len(my_file)):\n",
    "        en = my_file.iloc[i][0]\n",
    "        fr = my_file.iloc[i][1]\n",
    "        etof[en] = fr\n",
    "        \n",
    "    return etof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "43b3ea3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the English to French training dictionary is 5000\n",
      "The length of the English to French test dictionary is 5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_fr_train = get_dict('en-fr.train.txt')\n",
    "print('The length of the English to French training dictionary is', len(en_fr_train))\n",
    "en_fr_test = get_dict('en-fr.test.txt')\n",
    "print('The length of the English to French test dictionary is', len(en_fr_train))\n",
    "type(en_fr_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acbe9f8",
   "metadata": {},
   "source": [
    "#### Looking at the English French dictionary\n",
    "\n",
    "* `en_fr_train` is a dictionary where the key is the English word and the value\n",
    "is the French translation of that English word.\n",
    "```\n",
    "{'the': 'la',\n",
    " 'and': 'et',\n",
    " 'was': 'était',\n",
    " 'for': 'pour',\n",
    "```\n",
    "\n",
    "* `en_fr_test` is similar to `en_fr_train`, but is a test set.  We won't look at it\n",
    "until we get to testing.\n",
    "\n",
    "## 1.1 Generate embedding and transform matrices\n",
    "\n",
    "#### Exercise: Translating English dictionary to French by using embeddings\n",
    "\n",
    "You will now implement a function `get_matrices`, which takes the loaded data\n",
    "and returns matrices `X` and `Y`.\n",
    "\n",
    "Inputs:\n",
    "- `en_fr` : English to French dictionary\n",
    "- `en_embeddings` : English to embeddings dictionary\n",
    "- `fr_embeddings` : French to embeddings dictionary\n",
    "\n",
    "Returns:\n",
    "- Matrix `X` and matrix `Y`, where each row in X is the word embedding for an\n",
    "english word, and the same row in Y is the word embedding for the French\n",
    "version of that English word.\n",
    "\n",
    "<div style=\"width:image width px; font-size:100%; text-align:center;\">\n",
    "<img src='X_to_Y.jpg' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:800px;height:200px;\" /> Figure 2 </div>\n",
    "\n",
    "Use the `en_fr` dictionary to ensure that the ith row in the `X` matrix\n",
    "corresponds to the ith row in the `Y` matrix.\n",
    "\n",
    "**Instructions**: Complete the function `get_matrices()`:\n",
    "* Iterate over English words in `en_fr` dictionary.\n",
    "* Check if the word have both English and French embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6d7c6715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrices(en_fr,french_vecs,english_vecs):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        en_fr: English to French dictionary\n",
    "        french_vecs: French words to their corresponding word embeddings.\n",
    "        english_vecs: English words to their corresponding word embeddings.\n",
    "    Output: \n",
    "        X: a matrix where the columns are the English embeddings.\n",
    "        Y: a matrix where the columns correspong to the French embeddings.\n",
    "        R: the projection matrix that minimizes the F norm ||X R -Y||^2.\n",
    "    \"\"\"\n",
    "    \n",
    "    # X_l and Y_l are lists of the english and french word embeddings\n",
    "    X_l=list()\n",
    "    Y_l=list()\n",
    "    \n",
    "    # get the english words (the keys in the dictionary) and store in a set()\n",
    "    english_set=english_vecs.keys()\n",
    "    \n",
    "    # get the french words (the keys in the dictionary) and store in a set()\n",
    "    french_set=french_vecs.keys()\n",
    "    \n",
    "    # store the french words that are part of the english-french dictionary\n",
    "    french_words=set(en_fr.values())\n",
    "    \n",
    "    for en_word,fr_word in en_fr.items():\n",
    "        if fr_word in french_set and en_word in english_set:\n",
    "            en_vec=english_vecs[en_word]\n",
    "            \n",
    "            fr_vec=french_vecs[fr_word]\n",
    "            \n",
    "            X_l.append(en_vec)\n",
    "            \n",
    "            Y_l.append(fr_vec)\n",
    "    \n",
    "    X=np.vstack(X_l)\n",
    "    \n",
    "    Y=np.vstack(Y_l)\n",
    "    \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d73f9f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.08007812,  0.10498047,  0.04980469, ...,  0.00366211,\n",
       "         0.04760742, -0.06884766],\n",
       "       [ 0.02600098, -0.00189209,  0.18554688, ..., -0.12158203,\n",
       "         0.22167969, -0.02197266],\n",
       "       [-0.01177979, -0.04736328,  0.04467773, ...,  0.07128906,\n",
       "        -0.03491211,  0.02416992],\n",
       "       ...,\n",
       "       [-0.17089844,  0.17871094, -0.06494141, ..., -0.10644531,\n",
       "        -0.31640625, -0.09326172],\n",
       "       [-0.21875   ,  0.09179688,  0.03637695, ..., -0.015625  ,\n",
       "        -0.27148438,  0.14941406],\n",
       "       [-0.00418091,  0.0703125 , -0.04516602, ..., -0.16015625,\n",
       "         0.09326172, -0.15039062]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, Y_train = get_matrices(\n",
    "    en_fr_train, fr_embeddings_subset, en_embeddings_subset)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb809899",
   "metadata": {},
   "source": [
    "# 2. Translations\n",
    "\n",
    "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='e_to_f.jpg' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:700px;height:200px;\" /> Figure 1 </div>\n",
    "\n",
    "Write a program that translates English words to French words using word embeddings and vector space models. \n",
    "\n",
    "## 2.1 Translation as linear transformation of embeddings\n",
    "\n",
    "Given dictionaries of English and French word embeddings you will create a transformation matrix `R`\n",
    "* Given an English word embedding, $\\mathbf{e}$, you can multiply $\\mathbf{eR}$ to get a new word embedding $\\mathbf{f}$.\n",
    "    * Both $\\mathbf{e}$ and $\\mathbf{f}$ are [row vectors](https://en.wikipedia.org/wiki/Row_and_column_vectors).\n",
    "* You can then compute the nearest neighbors to `f` in the french embeddings and recommend the word that is most similar to the transformed word embedding.\n",
    "\n",
    "### Describing translation as the minimization problem\n",
    "\n",
    "Find a matrix `R` that minimizes the following equation. \n",
    "\n",
    "$$\\arg \\min _{\\mathbf{R}}\\| \\mathbf{X R} - \\mathbf{Y}\\|_{F}\\tag{1} $$\n",
    "\n",
    "### Frobenius norm\n",
    "\n",
    "The Frobenius norm of a matrix $A$ (assuming it is of dimension $m,n$) is defined as the square root of the sum of the absolute squares of its elements:\n",
    "\n",
    "$$\\|\\mathbf{A}\\|_{F} \\equiv \\sqrt{\\sum_{i=1}^{m} \\sum_{j=1}^{n}\\left|a_{i j}\\right|^{2}}\\tag{2}$$\n",
    "\n",
    "### Actual loss function\n",
    "In the real world applications, the Frobenius norm loss:\n",
    "\n",
    "$$\\| \\mathbf{XR} - \\mathbf{Y}\\|_{F}$$\n",
    "\n",
    "is often replaced by it's squared value divided by $m$:\n",
    "\n",
    "$$ \\frac{1}{m} \\|  \\mathbf{X R} - \\mathbf{Y} \\|_{F}^{2}$$\n",
    "\n",
    "where $m$ is the number of examples (rows in $\\mathbf{X}$).\n",
    "\n",
    "* The same R is found when using this loss function versus the original Frobenius norm.\n",
    "* The reason for taking the square is that it's easier to compute the gradient of the squared Frobenius.\n",
    "* The reason for dividing by $m$ is that we're more interested in the average loss per embedding than the  loss for the entire training set.\n",
    "    * The loss for all training set increases with more words (training examples),\n",
    "    so taking the average helps us to track the average loss regardless of the size of the training set.\n",
    "    \n",
    "##### [Optional] Detailed explanation why we use norm squared instead of the norm:\n",
    "<details>\n",
    "<summary>\n",
    "    Click for optional details\n",
    "</summary>\n",
    "    <p>\n",
    "        <ul>\n",
    "            <li>The norm is always nonnegative (we're summing up absolute values), and so is the square. \n",
    "            <li> When we take the square of all non-negative (positive or zero) numbers, the order of the data is preserved.  \n",
    "            <li> For example, if 3 > 2, 3^2 > 2^2\n",
    "            <li> Using the norm or squared norm in gradient descent results in the same <i>location</i> of the minimum.\n",
    "            <li> Squaring cancels the square root in the Frobenius norm formula. Because of the <a href=\"https://en.wikipedia.org/wiki/Chain_rule\"> chain rule</a>, we would have to do more calculations if we had a square root in our expression for summation.\n",
    "            <li> Dividing the function value by the positive number doesn't change the optimum of the function, for the same reason as described above.\n",
    "            <li> We're interested in transforming English embedding into the French. Thus, it is more important to measure average loss per embedding than the loss for the entire dictionary (which increases as the number of words in the dictionary increases).\n",
    "        </ul>\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcb2514",
   "metadata": {},
   "source": [
    "### Exercise: Implementing translation mechanism described in this section.\n",
    "\n",
    "#### Step 1: Computing the loss\n",
    "* The loss function will be squared Frobenoius norm of the difference between\n",
    "matrix and its approximation, divided by the number of training examples $m$.\n",
    "* Its formula is:\n",
    "$$ L(X, Y, R)=\\frac{1}{m}\\sum_{i=1}^{m} \\sum_{j=1}^{n}\\left( a_{i j} \\right)^{2}$$\n",
    "\n",
    "where $a_{i j}$ is value in $i$th row and $j$th column of the matrix $\\mathbf{XR}-\\mathbf{Y}$.\n",
    "\n",
    "\n",
    "#### Instructions: complete the `compute_loss()` function\n",
    "\n",
    "* Compute the approximation of `Y` by matrix multiplying `X` and `R`\n",
    "* Compute difference `XR - Y`\n",
    "* Compute the squared Frobenius norm of the difference and divide it by $m$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "740afab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(X,Y,R):\n",
    "    '''\n",
    "    Inputs: \n",
    "        X: a matrix of dimension (m,n) where the columns are the English embeddings.\n",
    "        Y: a matrix of dimension (m,n) where the columns correspong to the French embeddings.\n",
    "        R: a matrix of dimension (n,n) - transformation matrix from English to French vector space embeddings.\n",
    "    Outputs:\n",
    "        L: a matrix of dimension (m,n) - the value of the loss function for given X, Y and R.\n",
    "    '''\n",
    "    \n",
    "    m=X.shape[0]\n",
    "    \n",
    "    diff=np.dot(X,R)-Y\n",
    "    \n",
    "    diff_squared=diff**2\n",
    "    \n",
    "    sum_diff_squared=np.sum(diff_squared)\n",
    "    \n",
    "    loss=sum_diff_squared/m\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577705df",
   "metadata": {},
   "source": [
    "### Step 2: Computing the gradient of loss in respect to transform matrix R\n",
    "\n",
    "* Calculate the gradient of the loss with respect to transform matrix `R`.\n",
    "* The gradient is a matrix that encodes how much a small change in `R`\n",
    "affect the change in the loss function.\n",
    "* The gradient gives us the direction in which we should decrease `R`\n",
    "to minimize the loss.\n",
    "* $m$ is the number of training examples (number of rows in $X$).\n",
    "* The formula for the gradient of the loss function $𝐿(𝑋,𝑌,𝑅)$ is:\n",
    "\n",
    "$$\\frac{d}{dR}𝐿(𝑋,𝑌,𝑅)=\\frac{d}{dR}\\Big(\\frac{1}{m}\\| X R -Y\\|_{F}^{2}\\Big) = \\frac{2}{m}X^{T} (X R - Y)$$\n",
    "\n",
    "**Instructions**: Complete the `compute_gradient` function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "64215724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(X,Y,R):\n",
    "    '''\n",
    "    Inputs: \n",
    "        X: a matrix of dimension (m,n) where the columns are the English embeddings.\n",
    "        Y: a matrix of dimension (m,n) where the columns correspong to the French embeddings.\n",
    "        R: a matrix of dimension (n,n) - transformation matrix from English to French vector space embeddings.\n",
    "    Outputs:\n",
    "        g: a matrix of dimension (n,n) - gradient of the loss function L for given X, Y and R.\n",
    "    '''\n",
    "    m=X.shape[0]\n",
    "    \n",
    "    gradient=np.dot(X.T,np.dot(X,R)-Y)*(2/m)\n",
    "    \n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363ee8d6",
   "metadata": {},
   "source": [
    "### Step 3: Finding the optimal R with gradient descent algorithm\n",
    "\n",
    "#### Gradient descent\n",
    "\n",
    "[Gradient descent](https://ml-cheatsheet.readthedocs.io/en/latest/gradient_descent.html) is an iterative algorithm which is used in searching for the optimum of the function. \n",
    "* Earlier, we've mentioned that the gradient of the loss with respect to the matrix encodes how much a tiny change in some coordinate of that matrix affect the change of loss function.\n",
    "* Gradient descent uses that information to iteratively change matrix `R` until we reach a point where the loss is minimized. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3b9cb9",
   "metadata": {},
   "source": [
    "Training with a fixed number of iterations\n",
    "\n",
    "Most of the time we iterate for a fixed number of training steps rather than iterating until the loss falls below a threshold.\n",
    "\n",
    "##### OPTIONAL: explanation for fixed number of iterations\n",
    "<details>\n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>click here for detailed discussion</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li> You cannot rely on training loss getting low -- what you really want is the validation loss to go down, or validation accuracy to go up. And indeed - in some cases people train until validation accuracy reaches a threshold, or -- commonly known as \"early stopping\" -- until the validation accuracy starts to go down, which is a sign of over-fitting.\n",
    "    </li>\n",
    "    <li>\n",
    "    Why not always do \"early stopping\"? Well, mostly because well-regularized models on larger data-sets never stop improving. Especially in NLP, you can often continue training for months and the model will continue getting slightly and slightly better. This is also the reason why it's hard to just stop at a threshold -- unless there's an external customer setting the threshold, why stop, where do you put the threshold?\n",
    "    </li>\n",
    "    <li>Stopping after a certain number of steps has the advantage that you know how long your training will take - so you can keep some sanity and not train for months. You can then try to get the best performance within this time budget. Another advantage is that you can fix your learning rate schedule -- e.g., lower the learning rate at 10% before finish, and then again more at 1% before finishing. Such learning rate schedules help a lot, but are harder to do if you don't know how long you're training.\n",
    "    </li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e0f8b7",
   "metadata": {},
   "source": [
    "Pseudocode:\n",
    "1. Calculate gradient $g$ of the loss with respect to the matrix $R$.\n",
    "2. Update $R$ with the formula:\n",
    "$$R_{\\text{new}}= R_{\\text{old}}-\\alpha g$$\n",
    "\n",
    "Where $\\alpha$ is the learning rate, which is a scalar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c46d20",
   "metadata": {},
   "source": [
    "#### Instructions: Implement `align_embeddings()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6f50d7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_embeddings(X,Y,train_steps=100,learning_rate=0.0003):\n",
    "    np.random.seed(129)\n",
    "    \n",
    "    R = np.random.rand(X.shape[1],X.shape[1])\n",
    "    \n",
    "    for i in range(train_steps):\n",
    "        if i%25 == 0:\n",
    "            print(\"loss at iteration {} is {:.4f}\".format(i,compute_loss(X,Y,R)))\n",
    "        \n",
    "        gradient = compute_gradient(X,Y,R)\n",
    "        \n",
    "        R -= learning_rate*gradient\n",
    "        \n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ed3f31c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at iteration 0 is 3.7242\n",
      "loss at iteration 25 is 3.6283\n",
      "loss at iteration 50 is 3.5350\n",
      "loss at iteration 75 is 3.4442\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "np.random.seed(129)\n",
    "m = 10\n",
    "n = 5\n",
    "X = np.random.rand(m, n)\n",
    "Y = np.random.rand(m, n) * .1\n",
    "R = align_embeddings(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e81b39e",
   "metadata": {},
   "source": [
    "## Calculate transformation matrix R\n",
    "\n",
    "Using those the training set, find the transformation matrix $\\mathbf{R}$ by calling the function `align_embeddings()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "76d04c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at iteration 0 is 963.0146\n",
      "loss at iteration 25 is 97.8292\n",
      "loss at iteration 50 is 26.8329\n",
      "loss at iteration 75 is 9.7893\n",
      "loss at iteration 100 is 4.3776\n",
      "loss at iteration 125 is 2.3281\n",
      "loss at iteration 150 is 1.4480\n",
      "loss at iteration 175 is 1.0338\n",
      "loss at iteration 200 is 0.8251\n",
      "loss at iteration 225 is 0.7145\n",
      "loss at iteration 250 is 0.6534\n",
      "loss at iteration 275 is 0.6185\n",
      "loss at iteration 300 is 0.5981\n",
      "loss at iteration 325 is 0.5858\n",
      "loss at iteration 350 is 0.5782\n",
      "loss at iteration 375 is 0.5735\n"
     ]
    }
   ],
   "source": [
    "R_train = align_embeddings(X_train, Y_train, train_steps=400, learning_rate=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea92a9e",
   "metadata": {},
   "source": [
    "## 2.2 Testing the translation\n",
    "\n",
    "### k-Nearest neighbors algorithm\n",
    "\n",
    "[k-Nearest neighbors algorithm](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) \n",
    "* k-NN is a method which takes a vector as input and finds the other vectors in the dataset that are closest to it. \n",
    "* The 'k' is the number of \"nearest neighbors\" to find (e.g. k=2 finds the closest two neighbors).\n",
    "\n",
    "### Searching for the translation embedding\n",
    "Since we're approximating the translation function from English to French embeddings by a linear transformation matrix $\\mathbf{R}$, most of the time we won't get the exact embedding of a French word when we transform embedding $\\mathbf{e}$ of some particular English word into the French embedding space. \n",
    "* This is where $k$-NN becomes really useful! By using $1$-NN with $\\mathbf{eR}$ as input, we can search for an embedding $\\mathbf{f}$ (as a row) in the matrix $\\mathbf{Y}$ which is the closest to the transformed vector $\\mathbf{eR}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cffc9c",
   "metadata": {},
   "source": [
    "### Cosine similarity\n",
    "Cosine similarity between vectors $u$ and $v$ calculated as the cosine of the angle between them.\n",
    "The formula is \n",
    "\n",
    "$$\\cos(u,v)=\\frac{u\\cdot v}{\\left\\|u\\right\\|\\left\\|v\\right\\|}$$\n",
    "\n",
    "* $\\cos(u,v)$ = $1$ when $u$ and $v$ lie on the same line and have the same direction.\n",
    "* $\\cos(u,v)$ is $-1$ when they have exactly opposite directions.\n",
    "* $\\cos(u,v)$ is $0$ when the vectors are orthogonal (perpendicular) to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09484a8c",
   "metadata": {},
   "source": [
    "**Exercise**: Complete the function `nearest_neighbor()`\n",
    "\n",
    "Inputs:\n",
    "* Vector `v`,\n",
    "* A set of possible nearest neighbors `candidates`\n",
    "* `k` nearest neighbors to find.\n",
    "* The distance metric should be based on cosine similarity.\n",
    "* `cosine_similarity` function is already implemented and imported for you. It's arguments are two vectors and it returns the cosine of the angle between them.\n",
    "* Iterate over rows in `candidates`, and save the result of similarities between current row and vector `v` in a python list. Take care that similarities are in the same order as row vectors of `candidates`.\n",
    "* Now you can use [numpy argsort]( https://docs.scipy.org/doc/numpy/reference/generated/numpy.argsort.html#numpy.argsort) to sort the indices for the rows of `candidates`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b5f050ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(A,B):\n",
    "    cos=0\n",
    "    \n",
    "    dot=np.dot(A,B)\n",
    "    norma=np.linalg.norm(A)\n",
    "    normb=np.linalg.norm(B)\n",
    "    \n",
    "    return dot/(norma*normb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "022b7837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(v,candidates,k=1):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      - v, the vector you are going find the nearest neighbor for\n",
    "      - candidates: a set of vectors where we will find the neighbors\n",
    "      - k: top k nearest neighbors to find\n",
    "    Output:\n",
    "      - k_idx: the indices of the top k closest vectors in sorted form\n",
    "    \"\"\"\n",
    "    \n",
    "    similarity_l=[]\n",
    "    \n",
    "    for row in candidates:\n",
    "        cos_similarity=cosine_similarity(v,row)\n",
    "        similarity_l.append(cos_similarity)\n",
    "        \n",
    "    sorted_ids=np.argsort(similarity_l)\n",
    "    \n",
    "    k_idx=sorted_ids[-k:]\n",
    "    \n",
    "    return k_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d9012fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9 9 9]\n",
      " [1 0 5]\n",
      " [2 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "v = np.array([1, 0, 1])\n",
    "candidates = np.array([[1, 0, 5], [-2, 5, 3], [2, 0, 1], [6, -9, 5], [9, 9, 9]])\n",
    "print(candidates[knn(v, candidates, 3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a4d6f6",
   "metadata": {},
   "source": [
    "### Test your translation and compute its accuracy\n",
    "\n",
    "**Exercise**:\n",
    "Complete the function `test_vocabulary` which takes in English\n",
    "embedding matrix $X$, French embedding matrix $Y$ and the $R$\n",
    "matrix and returns the accuracy of translations from $X$ to $Y$ by $R$.\n",
    "\n",
    "* Iterate over transformed English word embeddings and check if the\n",
    "closest French word vector belongs to French word that is the actual\n",
    "translation.\n",
    "* Obtain an index of the closest French embedding by using\n",
    "`nearest_neighbor` (with argument `k=1`), and compare it to the index\n",
    "of the English embedding you have just transformed.\n",
    "* Keep track of the number of times you get the correct translation.\n",
    "* Calculate accuracy as $$\\text{accuracy}=\\frac{\\#(\\text{correct predictions})}{\\#(\\text{total predictions})}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7b3f8f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_vocabulary(X,Y,R):\n",
    "    '''\n",
    "    Input:\n",
    "        X: a matrix where the columns are the English embeddings.\n",
    "        Y: a matrix where the columns correspong to the French embeddings.\n",
    "        R: the transform matrix which translates word embeddings from\n",
    "        English to French word vector space.\n",
    "    Output:\n",
    "        accuracy: for the English to French capitals\n",
    "    '''\n",
    "    pred=np.dot(X,R)\n",
    "    num_correct=0\n",
    "    \n",
    "    for i in range(len(pred)):\n",
    "        pred_idx=knn(pred[i],Y)\n",
    "        \n",
    "        if pred_idx==i:\n",
    "            num_correct+=1\n",
    "    \n",
    "    accuracy=num_correct/len(pred)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f889aa",
   "metadata": {},
   "source": [
    "Let's see how is your translation mechanism working on the unseen data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "213cd2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, Y_val = get_matrices(en_fr_test, fr_embeddings_subset, en_embeddings_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9fc986b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on test set is 0.557\n"
     ]
    }
   ],
   "source": [
    "acc = test_vocabulary(X_val, Y_val, R_train)  # this might take a minute or two\n",
    "print(f\"accuracy on test set is {acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71845ee",
   "metadata": {},
   "source": [
    "You managed to translate words from one language to another language\n",
    "without ever seing them with almost 56% accuracy by using some basic\n",
    "linear algebra and learning a mapping of words from one language to another!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2122dc",
   "metadata": {},
   "source": [
    "# 3. LSH and document search\n",
    "\n",
    "In this part of the assignment, you will implement a more efficient version\n",
    "of k-nearest neighbors using locality sensitive hashing.\n",
    "You will then apply this to document search.\n",
    "\n",
    "* Process the tweets and represent each tweet as a vector (represent a\n",
    "document with a vector embedding).\n",
    "* Use locality sensitive hashing and k nearest neighbors to find tweets\n",
    "that are similar to a given tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7e88a292",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "all_tweets = all_positive_tweets + all_negative_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee993a2",
   "metadata": {},
   "source": [
    "### 3.2 Getting the document embeddings\n",
    "\n",
    "#### Bag-of-words (BOW) document models\n",
    "Text documents are sequences of words.\n",
    "* The ordering of words makes a difference. For example, sentences \"Apple pie is\n",
    "better than pepperoni pizza.\" and \"Pepperoni pizza is better than apple pie\"\n",
    "have opposite meanings due to the word ordering.\n",
    "* However, for some applications, ignoring the order of words can allow\n",
    "us to train an efficient and still effective model.\n",
    "* This approach is called Bag-of-words document model.\n",
    "\n",
    "#### Document embeddings\n",
    "* Document embedding is created by summing up the embeddings of all words\n",
    "in the document.\n",
    "* If we don't know the embedding of some word, we can ignore that word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00633a89",
   "metadata": {},
   "source": [
    "**Exercise**:\n",
    "Complete the `get_document_embedding()` function.\n",
    "* The function `get_document_embedding()` encodes entire document as a \"document\" embedding.\n",
    "* It takes in a docoument (as a string) and a dictionary, `en_embeddings`\n",
    "* It processes the document, and looks up the corresponding embedding of each word.\n",
    "* It then sums them up and returns the sum of all word vectors of that processed tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "428c3e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0a7b3807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "    stemmer=PorterStemmer()\n",
    "    stopwords_english=stopwords.words('english')\n",
    "    \n",
    "    # remove stock market tickers like $GE\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    # remove old style retweet text \"RT\"\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    # remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    # remove hashtags\n",
    "    # only removing the hash # sign from the word\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    \n",
    "    tokenizer=TweetTokenizer(preserve_case=False,strip_handles=True,\n",
    "                             reduce_len=True)\n",
    "    \n",
    "    tweet_tokens=tokenizer.tokenize(tweet)\n",
    "    \n",
    "    tweets_clean=[]\n",
    "    \n",
    "    for word in tweet_tokens:\n",
    "        if word not in stopwords_english and\\\n",
    "            word not in string.punctuation:\n",
    "            stem_word=stemmer.stem(word)\n",
    "            tweets_clean.append(stem_word)\n",
    "    \n",
    "    return tweets_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "258e03eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_embedding(tweet,en_embeddings):    \n",
    "    '''\n",
    "    Input:\n",
    "        - tweet: a string\n",
    "        - en_embeddings: a dictionary of word embeddings\n",
    "    Output:\n",
    "        - tweet_embedding: a\n",
    "    '''\n",
    "    \n",
    "    doc_embedding=np.zeros(300)\n",
    "    \n",
    "    processed_doc=process_tweet(tweet)\n",
    "    \n",
    "    for word in processed_doc:\n",
    "        doc_embedding+=en_embeddings.get(word,0)\n",
    "        \n",
    "    return doc_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "442041cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00268555, -0.15378189, -0.55761719, -0.07216644, -0.32263184])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "\n",
    "custom_tweet = \"RT @Twitter @chapagain Hello There! Have a great day. :) #good #morning http://chapagain.com.np\"\n",
    "\n",
    "tweet_embedding = get_document_embedding(custom_tweet, en_embeddings_subset)\n",
    "tweet_embedding[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2827bb0e",
   "metadata": {},
   "source": [
    "#### Store all document vectors into a dictionary\n",
    "Now, let's store all the tweet embeddings into a dictionary.\n",
    "Implement `get_document_vecs()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "de13cd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_vecs(all_docs,en_embeddings):\n",
    "    '''\n",
    "    Input:\n",
    "        - all_docs: list of strings - all tweets in our dataset.\n",
    "        - en_embeddings: dictionary with words as the keys and their embeddings as the values.\n",
    "    Output:\n",
    "        - document_vec_matrix: matrix of tweet embeddings.\n",
    "        - ind2Doc_dict: dictionary with indices of tweets in vecs as keys and their embeddings as the values.\n",
    "    '''\n",
    "    \n",
    "    ind2Doc_dict={}\n",
    "    \n",
    "    document_vec_l=[]\n",
    "    \n",
    "    for i,doc in enumerate(all_docs):\n",
    "        \n",
    "        # get the document embedding of the tweet\n",
    "        doc_embedding=get_document_embedding(doc,en_embeddings)\n",
    "        \n",
    "        ind2Doc_dict[i]=doc_embedding\n",
    "        \n",
    "        document_vec_l.append(doc_embedding)\n",
    "        \n",
    "    document_vec_matrix=np.vstack(document_vec_l)\n",
    "    \n",
    "    return document_vec_matrix,ind2Doc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7f2c8a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_vecs, ind2Tweet = get_document_vecs(all_tweets, en_embeddings_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1c9b21ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dictionary 10000\n",
      "shape of document_vecs (10000, 300)\n"
     ]
    }
   ],
   "source": [
    "print(f\"length of dictionary {len(ind2Tweet)}\")\n",
    "print(f\"shape of document_vecs {document_vecs.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5e1f8d",
   "metadata": {},
   "source": [
    "## 3.3 Looking up the tweets.\n",
    "\n",
    "Now you have a vector of dimension (m,d) where `m` is the number of tweets\n",
    "(10,000) and `d` is the dimension of the embeddings (300).  Now you\n",
    "will input a tweet, and use cosine similarity to see which tweet in our\n",
    "corpus is similar to your tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "36bf0971",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tweet = 'i am sad'\n",
    "process_tweet(my_tweet)\n",
    "tweet_embedding = get_document_embedding(my_tweet, en_embeddings_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c07018a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@zoeeylim sad sad sad kid :( it's ok I help you watch the match HAHAHAHAHA\n"
     ]
    }
   ],
   "source": [
    "idx = np.argmax(cosine_similarity(document_vecs, tweet_embedding))\n",
    "print(all_tweets[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc25c6f",
   "metadata": {},
   "source": [
    "## 3.4 Finding the most similar tweets with LSH\n",
    "\n",
    "You will now implement locality sensitive hashing (LSH) to identify the most similar tweet.\n",
    "* Instead of looking at all 10,000 vectors, you can just search a subset to find\n",
    "its nearest neighbors.\n",
    "\n",
    "Let's say your data points are plotted like this:\n",
    "\n",
    "\n",
    "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='one.png' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:400px;height:200px;\" /> Figure 3 </div>\n",
    "\n",
    "You can divide the vector space into regions and search within one region for nearest neighbors of a given vector.\n",
    "\n",
    "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='four.png' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:400px;height:200px;\" /> Figure 4 </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a32c82b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors is 10000 and each has 300 dimensions.\n"
     ]
    }
   ],
   "source": [
    "N_VECS = len(all_tweets)       # This many vectors.\n",
    "N_DIMS = len(ind2Tweet[1])     # Vector dimensionality.\n",
    "print(f\"Number of vectors is {N_VECS} and each has {N_DIMS} dimensions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d67fca3",
   "metadata": {},
   "source": [
    "#### Choosing the number of planes\n",
    "\n",
    "* Each plane divides the space to $2$ parts.\n",
    "* So $n$ planes divide the space into $2^{n}$ hash buckets.\n",
    "* We want to organize 10,000 document vectors into buckets so that every bucket has about $~16$ planes.\n",
    "* For that we need $\\frac{10000}{16}=625$ buckets.\n",
    "* We're interested in $n$, number of planes, so that $2^{n}= 625$. Now, we can calculate $n=\\log_{2}625 = 9.29 \\approx 10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4dfde62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of planes. We use log2(256) to have ~16 vectors/bucket.\n",
    "N_PLANES = 10\n",
    "# Number of times to repeat the hashing to improve the search.\n",
    "N_UNIVERSES = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9accee8d",
   "metadata": {},
   "source": [
    "## 3.5 Getting the hash number for a vector\n",
    "\n",
    "For each vector, we need to get a unique number associated to that vector in order to assign it to a \"hash bucket\".\n",
    "\n",
    "### Hyperlanes in vector spaces\n",
    "* In $3$-dimensional vector space, the hyperplane is a regular plane. In $2$ dimensional vector space, the hyperplane is a line.\n",
    "* Generally, the hyperplane is subspace which has dimension $1$ lower than the original vector space has.\n",
    "* A hyperplane is uniquely defined by its normal vector.\n",
    "* Normal vector $n$ of the plane $\\pi$ is the vector to which all vectors in the plane $\\pi$ are orthogonal (perpendicular in $3$ dimensional case).\n",
    "\n",
    "### Using Hyperplanes to split the vector space\n",
    "We can use a hyperplane to split the vector space into $2$ parts.\n",
    "* All vectors whose dot product with a plane's normal vector is positive are on one side of the plane.\n",
    "* All vectors whose dot product with the plane's normal vector is negative are on the other side of the plane.\n",
    "\n",
    "### Encoding hash buckets\n",
    "* For a vector, we can take its dot product with all the planes, then encode this information to assign the vector to a single hash bucket.\n",
    "* When the vector is pointing to the opposite side of the hyperplane than normal, encode it by 0.\n",
    "* Otherwise, if the vector is on the same side as the normal vector, encode it by 1.\n",
    "* If you calculate the dot product with each plane in the same order for every vector, you've encoded each vector's unique hash ID as a binary number, like [0, 1, 1, ... 0]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6954be",
   "metadata": {},
   "source": [
    "### Implementing hash buckets\n",
    "\n",
    "We've initialized hash table `hashes` for you. It is list of `N_UNIVERSES` matrices, each describes its own hash table. Each matrix has `N_DIMS` rows and `N_PLANES` columns. Every column of that matrix is a `N_DIMS`-dimensional normal vector for each of `N_PLANES` hyperplanes which are used for creating buckets of the particular hash table.\n",
    "\n",
    "*Exercise*: Your task is to complete the function `hash_value_of_vector` which places vector `v` in the correct hash bucket.\n",
    "\n",
    "* First multiply your vector `v`, with a corresponding plane. This will give you a vector of dimension $(1,\\text{N_planes})$.\n",
    "* You will then convert every element in that vector to 0 or 1.\n",
    "* You create a hash vector by doing the following: if the element is negative, it becomes a 0, otherwise you change it to a 1.\n",
    "* You then compute the unique number for the vector by iterating over `N_PLANES`\n",
    "* Then you multiply $2^i$ times the corresponding bit (0 or 1).\n",
    "* You will then store that sum in the variable `hash_value`.\n",
    "\n",
    "**Intructions:** Create a hash for the vector in the function below.\n",
    "Use this formula:\n",
    "\n",
    "$$ hash = \\sum_{i=0}^{N-1} \\left( 2^{i} \\times h_{i} \\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dddfd04",
   "metadata": {},
   "source": [
    "#### Create the sets of planes\n",
    "* Create multiple (25) sets of planes (the planes that divide up the region).\n",
    "* You can think of these as 25 separate ways of dividing up the vector space with a different set of planes.\n",
    "* Each element of this list contains a matrix with 300 rows (the word vector have 300 dimensions), and 10 columns (there are 10 planes in each \"universe\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9dd50877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.76405235,  0.40015721,  0.97873798, ..., -0.15135721,\n",
       "         -0.10321885,  0.4105985 ],\n",
       "        [ 0.14404357,  1.45427351,  0.76103773, ..., -0.20515826,\n",
       "          0.3130677 , -0.85409574],\n",
       "        [-2.55298982,  0.6536186 ,  0.8644362 , ..., -0.18718385,\n",
       "          1.53277921,  1.46935877],\n",
       "        ...,\n",
       "        [-0.95051795, -0.46399642, -0.17724662, ...,  1.07230065,\n",
       "         -0.50370944, -0.58701629],\n",
       "        [-0.37817805,  0.8528891 , -2.14811848, ...,  0.44768322,\n",
       "         -0.66219144, -1.57760707],\n",
       "        [-0.34056003, -1.30322008,  0.46675065, ..., -0.19240421,\n",
       "         -1.21251574, -0.08059852]]),\n",
       " array([[ 1.59327362,  0.5687224 , -0.11448705, ...,  0.09942199,\n",
       "         -1.53061624,  0.32762318],\n",
       "        [ 0.27919649, -0.37705121,  0.004175  , ..., -0.01155552,\n",
       "          0.83949067, -0.17392993],\n",
       "        [-2.81066805, -0.15065364, -0.48104402, ...,  1.57030391,\n",
       "         -0.62594311,  0.47232789],\n",
       "        ...,\n",
       "        [ 2.4529964 , -1.87363434, -0.06810869, ..., -1.13919986,\n",
       "         -0.01039987, -0.5209394 ],\n",
       "        [-1.08922121, -0.34620334, -1.84540722, ...,  0.75498708,\n",
       "          1.35942026,  0.69607204],\n",
       "        [ 0.68220139, -0.01121416,  1.3447604 , ..., -0.53788475,\n",
       "          0.39344443,  0.28651827]]),\n",
       " array([[ 2.04253623, -0.91946118,  0.11467003, ..., -1.65465749,\n",
       "          0.03723274,  1.2703013 ],\n",
       "        [-0.14327661,  0.79525521, -0.07207248, ...,  0.16821438,\n",
       "         -0.96884614,  0.30965402],\n",
       "        [ 0.94010787, -0.16339035, -0.32088231, ..., -0.21062455,\n",
       "          2.61180002, -0.81709612],\n",
       "        ...,\n",
       "        [ 2.04415109, -2.02331736, -0.00806795, ..., -0.0456275 ,\n",
       "          0.02881432, -0.55661421],\n",
       "        [-0.16021257,  0.78944385, -2.34358715, ...,  0.01852555,\n",
       "          0.29105886,  1.80883262],\n",
       "        [-1.21725014, -1.47505026, -0.5276564 , ..., -0.81262409,\n",
       "         -1.08104703,  0.68411634]]),\n",
       " array([[ 1.41707927,  0.44372873, -0.07697271, ...,  1.68253025,\n",
       "         -0.14711308, -0.36785922],\n",
       "        [ 0.13737488, -0.22010714, -2.50142391, ..., -0.24585849,\n",
       "         -1.38965324, -0.07863102],\n",
       "        [ 0.97951276, -0.2071324 , -0.49472676, ..., -0.90031684,\n",
       "         -1.24777704, -0.17718447],\n",
       "        ...,\n",
       "        [ 1.95106836,  0.162215  , -1.40234693, ...,  1.87026213,\n",
       "         -0.10898912, -0.3058429 ],\n",
       "        [-0.70819207, -0.39114358, -0.70890964, ..., -0.38692027,\n",
       "         -0.97105659, -0.06758472],\n",
       "        [ 1.13296138,  0.65293379,  1.23044972, ..., -1.9974298 ,\n",
       "         -0.03192091,  0.22396576]]),\n",
       " array([[ 0.94550839,  0.42292354, -1.17568   , ..., -0.55083369,\n",
       "         -0.671678  , -0.69682734],\n",
       "        [-1.39615542, -0.56004991,  0.32467708, ...,  0.32633722,\n",
       "          1.47748905,  1.05073533],\n",
       "        [-0.50255845, -2.58274641, -1.39639191, ...,  1.07102336,\n",
       "          0.97791071,  0.94653999],\n",
       "        ...,\n",
       "        [ 0.79886511, -1.73523959, -0.84881547, ...,  0.02277966,\n",
       "          1.1678683 ,  1.59774618],\n",
       "        [ 0.6137764 , -0.15608997, -1.2249264 , ..., -0.60965648,\n",
       "          0.84140079,  0.85746568],\n",
       "        [ 0.81949888,  1.91662273, -1.24813317, ...,  0.75309415,\n",
       "         -0.58103281, -0.19837974]]),\n",
       " array([[ 2.46998202,  0.58701674, -0.39735265, ..., -0.47222434,\n",
       "          0.14299328, -0.66437456],\n",
       "        [ 0.99917027, -0.72302268, -0.92426843, ...,  0.31610439,\n",
       "         -1.57050427, -3.04824739],\n",
       "        [-1.49115687, -0.56200169, -1.57622674, ...,  0.08419408,\n",
       "         -1.55967176, -2.39544732],\n",
       "        ...,\n",
       "        [-0.01937342,  1.16295043,  1.77070661, ..., -0.73180913,\n",
       "          0.96466776,  0.49123518],\n",
       "        [ 0.50052775, -0.18868118,  0.64687017, ..., -0.38524616,\n",
       "          0.25919114, -0.26827015],\n",
       "        [-1.57230916,  0.33204511,  3.20068801, ..., -0.01332215,\n",
       "         -0.14629813,  0.05587194]]),\n",
       " array([[ 0.00601421,  0.75277121,  0.23244057, ..., -0.1153475 ,\n",
       "         -2.20388449, -0.3664562 ],\n",
       "        [ 0.83005477,  0.7540669 , -1.21070921, ..., -0.5798934 ,\n",
       "          1.10881389, -0.57273855],\n",
       "        [ 0.6018814 ,  1.74575134, -0.75396215, ...,  0.51803208,\n",
       "          0.30724114, -0.3721626 ],\n",
       "        ...,\n",
       "        [ 1.14327091,  1.63782241,  0.10389108, ...,  0.84824417,\n",
       "         -0.82786188,  1.21659189],\n",
       "        [-0.18421927,  0.53836046,  0.01364638, ..., -1.80591584,\n",
       "          1.10025959, -0.69315417],\n",
       "        [-0.20907556,  0.00679116, -1.02318427, ...,  0.45351871,\n",
       "          0.16812991,  1.60241499]]),\n",
       " array([[-0.98566722, -1.6728118 ,  1.18044823, ...,  0.14875635,\n",
       "         -1.31750439,  0.57227433],\n",
       "        [-0.85582449,  1.04464875, -0.97740152, ...,  0.87414065,\n",
       "          0.19235327,  0.47711263],\n",
       "        [ 0.52197264,  1.0568251 ,  0.1275016 , ...,  0.73907764,\n",
       "          1.3197847 ,  0.3206359 ],\n",
       "        ...,\n",
       "        [-0.05851771,  0.17006531,  0.49646973, ...,  1.17291116,\n",
       "         -0.27391063,  1.63131787],\n",
       "        [-0.13292076,  0.20383489, -0.72909416, ..., -0.7045808 ,\n",
       "         -0.35610334,  0.08836582],\n",
       "        [-0.43020784, -1.24787186,  0.49894213, ..., -0.06510899,\n",
       "          1.02225516, -0.55198059]]),\n",
       " array([[-0.33893166,  1.57640906, -0.70535388, ..., -0.22741978,\n",
       "          0.75084512,  1.44663327],\n",
       "        [ 0.64882692, -0.99546286, -0.66520792, ..., -1.54800682,\n",
       "         -1.36305145, -0.44435487],\n",
       "        [ 1.60246093, -1.00532983,  0.73481785, ..., -0.52941798,\n",
       "          0.31603206,  0.09240044],\n",
       "        ...,\n",
       "        [ 1.20655642,  0.50205159, -0.07580891, ...,  1.68352248,\n",
       "         -1.11107693,  0.30876279],\n",
       "        [-0.53063097,  1.44137649,  0.09407437, ..., -0.96459203,\n",
       "         -1.88313223,  0.37315025],\n",
       "        [ 0.70973394,  0.86334153,  0.05724138, ...,  1.27538889,\n",
       "          0.10144695, -0.27204244]]),\n",
       " array([[ 0.74900351, -0.03181051, -2.51188953, ...,  2.43514657,\n",
       "          0.94394338,  1.76856509],\n",
       "        [-1.75936945, -0.94711047, -0.34517837, ...,  0.70511188,\n",
       "          0.4522476 ,  0.15968168],\n",
       "        [-0.39101929,  1.89144541,  0.11215856, ...,  0.77545188,\n",
       "          1.61541317,  1.34067168],\n",
       "        ...,\n",
       "        [ 1.12215205,  0.02709386, -2.26776238, ..., -0.06436447,\n",
       "         -1.55594322,  1.64327418],\n",
       "        [ 0.59462254,  0.42028309,  0.01099687, ...,  0.04617153,\n",
       "          1.53335584,  1.91029705],\n",
       "        [ 0.069245  ,  1.03930909,  0.11820404, ..., -1.51127631,\n",
       "          0.97684383,  1.25550065]]),\n",
       " array([[ 0.37123214,  0.30478389,  0.5041246 , ..., -0.77387046,\n",
       "         -0.89032813,  0.03039898],\n",
       "        [-1.57962994, -1.88076332,  0.47159232, ...,  0.68150127,\n",
       "         -1.29966484,  0.76419073],\n",
       "        [ 0.1130914 ,  0.34764209,  0.89415241, ..., -2.13520448,\n",
       "          0.9271841 ,  1.39952831],\n",
       "        ...,\n",
       "        [ 0.48981677, -1.80718945, -0.08602385, ..., -0.94980221,\n",
       "         -0.00877275, -0.97713538],\n",
       "        [-0.87841061,  1.86100283,  0.4241185 , ..., -0.92718119,\n",
       "          1.20494786, -0.74875146],\n",
       "        [-2.49482088,  2.32487775,  0.19480414, ...,  0.10748659,\n",
       "          0.24515372,  1.47414784]]),\n",
       " array([[-1.37149662,  1.4597207 , -0.22401078, ...,  1.0413499 ,\n",
       "          1.08241869, -1.39004597],\n",
       "        [ 0.83834175, -0.57289882, -0.76081851, ...,  0.06027225,\n",
       "          1.74493228,  1.39112323],\n",
       "        [-0.28240203, -0.02499417, -1.87606428, ...,  1.32655367,\n",
       "          0.31575964,  0.73492535],\n",
       "        ...,\n",
       "        [-0.06224754,  0.71178265, -1.00410168, ..., -1.14104757,\n",
       "         -0.61284604,  0.54193745],\n",
       "        [ 0.36898444,  0.85376234, -0.73072963, ..., -0.41349685,\n",
       "         -0.38311601, -0.11942132],\n",
       "        [ 0.21321935,  0.892279  ,  1.19945286, ..., -0.42897954,\n",
       "          1.29701828,  0.53860456]]),\n",
       " array([[-0.39211458,  0.37994571, -0.21686041, ...,  0.81426855,\n",
       "          0.06298979,  1.07827093],\n",
       "        [-0.30979936,  1.1608968 , -0.04503248, ..., -0.6024253 ,\n",
       "          0.08043151,  1.17021376],\n",
       "        [ 1.23906037,  0.04229571, -0.26607551, ...,  0.59767491,\n",
       "          0.20931697,  1.30532923],\n",
       "        ...,\n",
       "        [-0.04918301,  1.01998458, -0.50865281, ...,  1.28011066,\n",
       "          0.51456182, -0.28151665],\n",
       "        [-1.85048306, -1.49681542,  0.56774797, ...,  0.23897297,\n",
       "         -0.65803459,  1.46566558],\n",
       "        [-0.51197543,  0.36340248,  0.83786201, ...,  1.27531056,\n",
       "         -1.57443754, -0.30533874]]),\n",
       " array([[-0.76553314,  1.05107809,  0.80043629, ..., -0.52678026,\n",
       "         -0.78692849, -0.41159605],\n",
       "        [-1.19917439, -0.57504479,  0.2946202 , ...,  0.66405584,\n",
       "          0.8327727 ,  1.84070049],\n",
       "        [ 0.78092946,  0.0030928 , -1.5531118 , ...,  0.13887845,\n",
       "          1.62936616,  0.17391151],\n",
       "        ...,\n",
       "        [-1.02225883,  2.60148034,  1.58083672, ...,  0.55926535,\n",
       "         -1.32594418,  0.59488465],\n",
       "        [ 0.40695022,  0.83989631, -0.4906891 , ...,  0.8426825 ,\n",
       "          1.01060387,  1.02456245],\n",
       "        [ 0.09443212,  1.45298788, -0.6713413 , ..., -0.48533571,\n",
       "          1.33798183, -1.67857884]]),\n",
       " array([[-1.04227179,  0.56759636,  1.6423405 , ...,  0.18304977,\n",
       "         -0.10643872,  2.54986432],\n",
       "        [ 0.13196338, -0.82988547,  0.25106348, ..., -1.38980626,\n",
       "          0.7125902 , -1.89002712],\n",
       "        [-1.28667571,  0.35071754,  1.00693072, ...,  1.37216777,\n",
       "          0.19860064, -0.50311308],\n",
       "        ...,\n",
       "        [-1.32062084,  0.65962923, -0.98848403, ..., -0.47471607,\n",
       "          2.0759609 ,  0.91176607],\n",
       "        [-1.35950435, -0.07507752,  1.07677159, ..., -1.43618466,\n",
       "          0.84167681, -0.72912574],\n",
       "        [-1.90003564,  0.16926515, -0.56439121, ...,  0.98232727,\n",
       "          0.05251446, -0.7168456 ]]),\n",
       " array([[ 0.56171276, -1.32767939,  0.04495191, ...,  1.17034275,\n",
       "          1.67076515,  0.9258809 ],\n",
       "        [-1.06424772,  1.11537317,  0.54194483, ...,  0.96075639,\n",
       "          0.11196952,  0.5639559 ],\n",
       "        [-1.71393945, -1.25678675, -0.22682532, ..., -1.07174685,\n",
       "          1.41427438,  0.21196183],\n",
       "        ...,\n",
       "        [-0.12511111,  0.0627681 ,  0.25259753, ...,  0.3575678 ,\n",
       "          0.3007902 , -2.10668246],\n",
       "        [ 0.6250435 , -0.66127409, -0.13412126, ..., -0.93957741,\n",
       "          0.30628275,  1.10161866],\n",
       "        [ 0.07502974,  0.1435457 , -0.81869009, ..., -2.7169762 ,\n",
       "         -1.14867462,  0.20888826]]),\n",
       " array([[-0.68078278, -3.06179614, -0.33133095, ..., -0.0289275 ,\n",
       "         -0.36369114, -1.24375129],\n",
       "        [-1.53007288, -1.17903228,  0.3857261 , ..., -0.71925893,\n",
       "          1.73009328, -0.5238712 ],\n",
       "        [ 1.06573879, -0.91893239, -0.55097381, ...,  0.10854789,\n",
       "          0.93891073,  0.63337248],\n",
       "        ...,\n",
       "        [-0.63440325,  2.29804985, -0.46306067, ...,  0.1016988 ,\n",
       "         -2.19942949,  0.10642248],\n",
       "        [-1.85710593,  1.50931958,  0.15327888, ...,  1.03539711,\n",
       "         -0.72295242, -0.33878311],\n",
       "        [ 1.60329336,  1.76091717, -1.2161747 , ...,  1.04627688,\n",
       "          0.28288818,  0.48279822]]),\n",
       " array([[ 0.23078051,  0.78233266,  0.95071077, ...,  1.08381258,\n",
       "          0.62275873,  0.09191466],\n",
       "        [ 0.62673123,  0.73698359, -0.46654889, ...,  0.20558559,\n",
       "         -1.77166433,  0.24282649],\n",
       "        [ 0.15708014, -0.81531822, -0.20220625, ..., -1.2548236 ,\n",
       "          1.54015203, -0.22708489],\n",
       "        ...,\n",
       "        [ 0.09015848, -0.47578519,  0.09562224, ...,  0.84024285,\n",
       "          1.36145093, -0.67512221],\n",
       "        [-0.31646101,  0.58100422, -1.0004386 , ...,  0.70731071,\n",
       "         -0.45332068, -2.05035123],\n",
       "        [ 0.72378599, -2.30811059,  0.79312116, ...,  0.36188398,\n",
       "         -0.54074075, -0.29531534]]),\n",
       " array([[-0.2099084 ,  1.02887155,  0.84151348, ...,  1.17844083,\n",
       "         -1.07346167,  2.35976481],\n",
       "        [ 1.17209618, -0.65658696,  0.71268971, ..., -1.04467634,\n",
       "         -1.20620161, -0.34074469],\n",
       "        [ 1.3466373 ,  0.60826819,  1.3727915 , ...,  0.61263052,\n",
       "          0.66440547, -0.99846567],\n",
       "        ...,\n",
       "        [-0.5186234 , -1.40509056, -0.33283914, ..., -1.04237268,\n",
       "          0.96406335, -0.45118461],\n",
       "        [ 0.90804108,  0.51636291,  0.91333213, ..., -1.08310345,\n",
       "         -0.4359258 ,  0.08621196],\n",
       "        [-0.6307891 , -0.09721204,  1.48322037, ..., -1.18801563,\n",
       "          0.89797418,  1.00034736]]),\n",
       " array([[ 0.89661082, -0.14929531, -0.13088692, ..., -0.49049205,\n",
       "          0.74371085,  1.93879456],\n",
       "        [ 1.63075594, -0.52041732,  0.35173195, ...,  0.70385592,\n",
       "         -0.27869695,  1.57496164],\n",
       "        [-0.06690149, -0.80042828, -0.7990863 , ..., -0.73016636,\n",
       "         -1.35315298, -0.88058043],\n",
       "        ...,\n",
       "        [-1.60450494, -1.7449423 , -0.86407432, ..., -0.96109389,\n",
       "         -0.63239193, -0.3632386 ],\n",
       "        [-0.77522958,  1.84687607, -0.03914752, ..., -0.11790954,\n",
       "          0.17687481, -0.0848587 ],\n",
       "        [ 0.97945158, -1.0092217 ,  1.50415164, ...,  0.89597933,\n",
       "         -2.11687003, -0.18395164]]),\n",
       " array([[-1.0776592 , -0.84229185, -0.25780784, ...,  0.32523471,\n",
       "          0.31034613, -0.6843566 ],\n",
       "        [-0.86417146, -1.35158415, -1.37097868, ...,  0.1678447 ,\n",
       "          0.10835583, -0.12594604],\n",
       "        [-1.43845731, -0.4379825 ,  0.60884188, ..., -1.0713446 ,\n",
       "         -0.59462978, -0.03634059],\n",
       "        ...,\n",
       "        [-0.26289008,  0.38056471,  0.81911678, ...,  0.15070666,\n",
       "         -1.91217948,  0.55743622],\n",
       "        [ 0.74304137, -0.24741506,  1.08761339, ...,  0.20242822,\n",
       "         -0.85224868,  2.23141754],\n",
       "        [-0.53538536, -0.17797137, -0.23837771, ..., -0.43852594,\n",
       "          0.43307801, -1.6723485 ]]),\n",
       " array([[ 0.45033641,  0.28669476, -0.38958154, ..., -0.62270435,\n",
       "         -0.28190427, -0.14504833],\n",
       "        [-0.18623296, -0.99477251,  0.12866543, ...,  1.45892748,\n",
       "          0.63364092, -0.82498176],\n",
       "        [ 1.10770281,  0.0143081 ,  2.68313947, ..., -0.56453243,\n",
       "         -1.40072335, -0.15032721],\n",
       "        ...,\n",
       "        [ 0.41405768,  0.73053492, -1.10095775, ..., -1.1608653 ,\n",
       "          0.01063238,  0.02138404],\n",
       "        [ 0.5337206 , -0.53036804, -1.80970075, ..., -0.22470694,\n",
       "          0.27274965, -0.01736036],\n",
       "        [-1.0712688 ,  0.22512589,  0.04713945, ..., -0.09004829,\n",
       "         -0.18790233, -1.15137321]]),\n",
       " array([[-0.36162771, -1.65832015, -0.18975004, ..., -1.34910343,\n",
       "         -1.0897932 , -2.07060765],\n",
       "        [ 0.71120045,  0.03750672, -0.64037395, ..., -1.30658449,\n",
       "          1.06669155,  0.99464385],\n",
       "        [-0.63097315,  0.24813889, -0.60187639, ...,  0.4139246 ,\n",
       "          0.5800729 ,  0.09423407],\n",
       "        ...,\n",
       "        [ 0.00482862,  0.28398856, -0.43651649, ...,  0.55702893,\n",
       "          0.57188323,  0.61067336],\n",
       "        [-0.30831777,  0.01449312, -0.26720895, ...,  1.26345957,\n",
       "          0.17705295, -1.4849346 ],\n",
       "        [-0.69912176, -0.72830341, -0.69395492, ..., -0.91664746,\n",
       "          1.57519128, -1.61819105]]),\n",
       " array([[-0.82530307, -1.07068019,  0.86984852, ..., -0.38365168,\n",
       "          1.06545146,  1.66664852],\n",
       "        [-0.12089371, -1.49954951,  1.23216195, ...,  0.53015421,\n",
       "         -1.19497771, -0.47804617],\n",
       "        [-0.52776657, -0.97285526,  0.46260889, ..., -0.61123553,\n",
       "         -0.95007919,  1.88248377],\n",
       "        ...,\n",
       "        [-0.47598073,  0.82231709,  0.59999785, ..., -2.36378973,\n",
       "          0.55361933,  1.0693031 ],\n",
       "        [-0.19847768,  0.52123691, -0.10103581, ...,  1.40530237,\n",
       "         -1.06329713, -0.95986031],\n",
       "        [ 1.3750353 , -0.41350481,  1.88462974, ..., -1.55673663,\n",
       "          0.14321934, -1.24624422]]),\n",
       " array([[ 0.1648119 , -1.96694025, -0.03627205, ..., -1.67333791,\n",
       "          0.45891932, -1.55603275],\n",
       "        [-0.28516023, -1.15245809, -0.78944402, ..., -2.11165988,\n",
       "         -0.25489341, -0.10006298],\n",
       "        [-0.23419627, -0.50752145, -1.00976054, ..., -0.87956057,\n",
       "         -0.22258831,  0.34197212],\n",
       "        ...,\n",
       "        [ 2.17678723,  0.53738663, -0.91871069, ...,  1.1228147 ,\n",
       "          1.36874616, -1.24635821],\n",
       "        [ 0.54863578,  0.31563208,  2.72183015, ...,  0.34074469,\n",
       "          0.89397612,  0.22362533],\n",
       "        [-1.2835609 ,  0.59335539, -0.87358641, ..., -0.56423433,\n",
       "         -1.1485287 ,  0.70873374]])]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "planes_l = [np.random.normal(size=(N_DIMS, N_PLANES))\n",
    "            for _ in range(N_UNIVERSES)]\n",
    "planes_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8776fa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C17 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def hash_value_of_vector(v, planes):\n",
    "    \"\"\"Create a hash for a vector; hash_id says which random hash to use.\n",
    "    Input:\n",
    "        - v:  vector of tweet. It's dimension is (1, N_DIMS)\n",
    "        - planes: matrix of dimension (N_DIMS, N_PLANES) - the set of planes that divide up the region\n",
    "    Output:\n",
    "        - res: a number which is used as a hash for your vector\n",
    "\n",
    "    \"\"\"\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    # for the set of planes,\n",
    "    # calculate the dot product between the vector and the matrix containing the planes\n",
    "    # remember that planes has shape (300, 10)\n",
    "    # The dot product will have the shape (1,10)\n",
    "    dot_product = np.dot(v,planes)\n",
    "    \n",
    "    # get the sign of the dot product (1,10) shaped vector\n",
    "    sign_of_dot_product = np.sign(dot_product)\n",
    "    \n",
    "    # set h to be false (eqivalent to 0 when used in operations) if the sign is negative,\n",
    "    # and true (equivalent to 1) if the sign is positive (1,10) shaped vector\n",
    "    h = sign_of_dot_product>=0\n",
    "\n",
    "    # remove extra un-used dimensions (convert this from a 2D to a 1D array)\n",
    "    h = np.squeeze(h)\n",
    "\n",
    "    # initialize the hash value to 0\n",
    "    hash_value = 0\n",
    "\n",
    "    n_planes = planes.shape[1]\n",
    "    for i in range(n_planes):\n",
    "        # increment the hash value by 2^i * h_i\n",
    "        hash_value += np.power(2,i)*h[i]\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # cast hash_value as an integer\n",
    "    hash_value = int(hash_value)\n",
    "\n",
    "    return hash_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e0d9ce2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The hash value for this vector, and the set of planes at index 0, is 768\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "idx = 0\n",
    "planes = planes_l[idx]  # get one 'universe' of planes to test the function\n",
    "vec = np.random.rand(1, 300)\n",
    "print(f\" The hash value for this vector,\",\n",
    "      f\"and the set of planes at index {idx},\",\n",
    "      f\"is {hash_value_of_vector(vec, planes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a3857f",
   "metadata": {},
   "source": [
    "## 3.5 Creating a hash table\n",
    "\n",
    "Given that you have a unique number for each vector (or tweet), You now want to create a hash table. You need a hash table, so that given a hash_id, you can quickly look up the corresponding vectors. This allows you to reduce your search by a significant amount of time.\n",
    "\n",
    "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='table.png' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:500px;height:200px;\" />  </div>\n",
    "\n",
    "We have given you the `make_hash_table` function, which maps the tweet vectors to a bucket and stores the vector there. It returns the `hash_table` and the `id_table`. The `id_table` allows you know which vector in a certain bucket corresponds to what tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6d1b42d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C19 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "# This is the code used to create a hash table: feel free to read over it\n",
    "def make_hash_table(vecs, planes):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        - vecs: list of vectors to be hashed.\n",
    "        - planes: the matrix of planes in a single \"universe\", with shape (embedding dimensions, number of planes).\n",
    "    Output:\n",
    "        - hash_table: dictionary - keys are hashes, values are lists of vectors (hash buckets)\n",
    "        - id_table: dictionary - keys are hashes, values are list of vectors id's\n",
    "                            (it's used to know which tweet corresponds to the hashed vector)\n",
    "    \"\"\"\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "\n",
    "    # number of planes is the number of columns in the planes matrix\n",
    "    num_of_planes = planes.shape[1]\n",
    "\n",
    "    # number of buckets is 2^(number of planes)\n",
    "    num_buckets = 2**num_of_planes\n",
    "\n",
    "    # create the hash table as a dictionary.\n",
    "    # Keys are integers (0,1,2.. number of buckets)\n",
    "    # Values are empty lists\n",
    "    hash_table = {i:[] for i in range(num_buckets)}\n",
    "\n",
    "    # create the id table as a dictionary.\n",
    "    # Keys are integers (0,1,2... number of buckets)\n",
    "    # Values are empty lists\n",
    "    id_table = {i:[] for i in range(num_buckets)}\n",
    "\n",
    "    # for each vector in 'vecs'\n",
    "    for i, v in enumerate(vecs):\n",
    "\n",
    "        # calculate the hash value for the vector\n",
    "        h = hash_value_of_vector(v,planes)\n",
    "        #print(h)\n",
    "        #print('******')\n",
    "        # store the vector into hash_table at key h,\n",
    "        # by appending the vector v to the list at key h\n",
    "        hash_table[h].append(v)\n",
    "\n",
    "        # store the vector's index 'i' (each document is given a unique integer 0,1,2...)\n",
    "        # the key is the h, and the 'i' is appended to the list at key h\n",
    "        id_table[h].append(i)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return hash_table, id_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ce1a2485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 10) \n",
      "The hash table at key 0 has 3 document vectors\n",
      "The id table at key 0 has 3\n",
      "The first 5 document indices stored at key 0 of are [3276, 3281, 3282]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "planes = planes_l[0]  # get one 'universe' of planes to test the function\n",
    "vec = np.random.rand(1, 300)\n",
    "print(planes.shape,'')\n",
    "\n",
    "tmp_hash_table, tmp_id_table = make_hash_table(document_vecs, planes)\n",
    "#print(tmp_hash_table[0])\n",
    "#print(tmp_id_table[0])\n",
    "print(f\"The hash table at key 0 has {len(tmp_hash_table[0])} document vectors\")\n",
    "print(f\"The id table at key 0 has {len(tmp_id_table[0])}\")\n",
    "print(f\"The first 5 document indices stored at key 0 of are {tmp_id_table[0][0:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ea20f9",
   "metadata": {},
   "source": [
    "### 3.6 Creating all hash tables\n",
    "\n",
    "You can now hash your vectors and store them in a hash table that\n",
    "would allow you to quickly look up and search for similar vectors.\n",
    "Run the cell below to create the hashes. By doing so, you end up having\n",
    "several tables which have all the vectors. Given a vector, you then\n",
    "identify the buckets in all the tables.  You can then iterate over the\n",
    "buckets and consider much fewer vectors. The more buckets you use, the\n",
    "more accurate your lookup will be, but also the longer it will take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cb901642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on hash universe #: 0\n",
      "working on hash universe #: 1\n",
      "working on hash universe #: 2\n",
      "working on hash universe #: 3\n",
      "working on hash universe #: 4\n",
      "working on hash universe #: 5\n",
      "working on hash universe #: 6\n",
      "working on hash universe #: 7\n",
      "working on hash universe #: 8\n",
      "working on hash universe #: 9\n",
      "working on hash universe #: 10\n",
      "working on hash universe #: 11\n",
      "working on hash universe #: 12\n",
      "working on hash universe #: 13\n",
      "working on hash universe #: 14\n",
      "working on hash universe #: 15\n",
      "working on hash universe #: 16\n",
      "working on hash universe #: 17\n",
      "working on hash universe #: 18\n",
      "working on hash universe #: 19\n",
      "working on hash universe #: 20\n",
      "working on hash universe #: 21\n",
      "working on hash universe #: 22\n",
      "working on hash universe #: 23\n",
      "working on hash universe #: 24\n"
     ]
    }
   ],
   "source": [
    "# Creating the hashtables\n",
    "hash_tables = []\n",
    "id_tables = []\n",
    "for universe_id in range(N_UNIVERSES):  # there are 25 hashes\n",
    "    print('working on hash universe #:', universe_id)\n",
    "    planes = planes_l[universe_id]\n",
    "    hash_table, id_table = make_hash_table(document_vecs, planes)\n",
    "    hash_tables.append(hash_table)\n",
    "    id_tables.append(id_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406dfef5",
   "metadata": {},
   "source": [
    "### Approximate K-NN\n",
    "\n",
    "Implement approximate K nearest neighbors using locality sensitive hashing,\n",
    "to search for documents that are similar to a given document at the\n",
    "index `doc_id`.\n",
    "\n",
    "##### Inputs\n",
    "* `doc_id` is the index into the document list `all_tweets`.\n",
    "* `v` is the document vector for the tweet in `all_tweets` at index `doc_id`.\n",
    "* `planes_l` is the list of planes (the global variable created earlier).\n",
    "* `k` is the number of nearest neighbors to search for.\n",
    "* `num_universes_to_use`: to save time, we can use fewer than the total\n",
    "number of available universes.  By default, it's set to `N_UNIVERSES`,\n",
    "which is $25$ for this assignment.\n",
    "\n",
    "The `approximate_knn` function finds a subset of candidate vectors that\n",
    "are in the same \"hash bucket\" as the input vector 'v'.  Then it performs\n",
    "the usual k-nearest neighbors search on this subset (instead of searching\n",
    "through all 10,000 tweets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7aaa4d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the code used to do the fast nearest neighbor search. Feel free to go over it\n",
    "def approximate_knn(doc_id, v, planes_l, k=1, num_universes_to_use=N_UNIVERSES):\n",
    "    \"\"\"Search for k-NN using hashes.\"\"\"\n",
    "    assert num_universes_to_use <= N_UNIVERSES\n",
    "\n",
    "    # Vectors that will be checked as p0ossible nearest neighbor\n",
    "    vecs_to_consider_l = list()\n",
    "\n",
    "    # list of document IDs\n",
    "    ids_to_consider_l = list()\n",
    "\n",
    "    # create a set for ids to consider, for faster checking if a document ID already exists in the set\n",
    "    ids_to_consider_set = set()\n",
    "\n",
    "    # loop through the universes of planes\n",
    "    for universe_id in range(num_universes_to_use):\n",
    "\n",
    "        # get the set of planes from the planes_l list, for this particular universe_id\n",
    "        planes = planes_l[universe_id]\n",
    "\n",
    "        # get the hash value of the vector for this set of planes\n",
    "        hash_value = hash_value_of_vector(v, planes)\n",
    "\n",
    "        # get the hash table for this particular universe_id\n",
    "        hash_table = hash_tables[universe_id]\n",
    "\n",
    "        # get the list of document vectors for this hash table, where the key is the hash_value\n",
    "        document_vectors_l = hash_table[hash_value]\n",
    "\n",
    "        # get the id_table for this particular universe_id\n",
    "        id_table = id_tables[universe_id]\n",
    "\n",
    "        # get the subset of documents to consider as nearest neighbors from this id_table dictionary\n",
    "        new_ids_to_consider = id_table[hash_value]\n",
    "\n",
    "        ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "\n",
    "        # remove the id of the document that we're searching\n",
    "        if doc_id in new_ids_to_consider:\n",
    "            new_ids_to_consider.remove(doc_id)\n",
    "            print(f\"removed doc_id {doc_id} of input vector from new_ids_to_search\")\n",
    "\n",
    "        # loop through the subset of document vectors to consider\n",
    "        for i, new_id in enumerate(new_ids_to_consider):\n",
    "\n",
    "            # if the document ID is not yet in the set ids_to_consider...\n",
    "            if new_id not in ids_to_consider_set:\n",
    "                # access document_vectors_l list at index i to get the embedding\n",
    "                # then append it to the list of vectors to consider as possible nearest neighbors\n",
    "                document_vector_at_i = document_vectors_l[i]\n",
    "                \n",
    "\n",
    "                # append the new_id (the index for the document) to the list of ids to consider\n",
    "                vecs_to_consider_l.append(document_vector_at_i)\n",
    "                ids_to_consider_l.append(new_id)\n",
    "                # also add the new_id to the set of ids to consider\n",
    "                # (use this to check if new_id is not already in the IDs to consider)\n",
    "                ids_to_consider_set.add(new_id)\n",
    "\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    # Now run k-NN on the smaller set of vecs-to-consider.\n",
    "    print(\"Fast considering %d vecs\" % len(vecs_to_consider_l))\n",
    "\n",
    "    # convert the vecs to consider set to a list, then to a numpy array\n",
    "    vecs_to_consider_arr = np.array(vecs_to_consider_l)\n",
    "\n",
    "    # call nearest neighbors on the reduced list of candidate vectors\n",
    "    nearest_neighbor_idx_l = knn(v, vecs_to_consider_arr, k=k)\n",
    "    print(nearest_neighbor_idx_l)\n",
    "    print(ids_to_consider_l)\n",
    "    # Use the nearest neighbor index list as indices into the ids to consider\n",
    "    # create a list of nearest neighbors by the document ids\n",
    "    nearest_neighbor_ids = [ids_to_consider_l[idx]\n",
    "                            for idx in nearest_neighbor_idx_l]\n",
    "\n",
    "    return nearest_neighbor_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "77977878",
   "metadata": {},
   "outputs": [],
   "source": [
    "#document_vecs, ind2Tweet\n",
    "doc_id = 0\n",
    "doc_to_search = all_tweets[doc_id]\n",
    "vec_to_search = document_vecs[doc_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a1ae0f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed doc_id 0 of input vector from new_ids_to_search\n",
      "removed doc_id 0 of input vector from new_ids_to_search\n",
      "removed doc_id 0 of input vector from new_ids_to_search\n",
      "removed doc_id 0 of input vector from new_ids_to_search\n",
      "removed doc_id 0 of input vector from new_ids_to_search\n",
      "Fast considering 77 vecs\n",
      "[26  8  0]\n",
      "[51, 105, 154, 160, 195, 253, 1876, 2478, 701, 1205, 1300, 1581, 1681, 1685, 2714, 4149, 4157, 4232, 4753, 5684, 6821, 9239, 213, 339, 520, 1729, 2140, 2786, 3028, 3162, 3259, 3654, 4002, 4047, 5263, 5492, 5538, 5649, 5656, 5729, 7076, 9063, 9207, 9789, 9927, 207, 254, 1302, 1480, 1815, 2298, 2620, 2741, 3525, 3837, 4704, 4871, 5327, 5386, 5923, 6033, 6371, 6762, 7288, 7472, 7774, 7790, 7947, 8061, 8224, 8276, 8892, 9096, 9153, 9175, 9323, 9740]\n"
     ]
    }
   ],
   "source": [
    "# Sample\n",
    "nearest_neighbor_ids = approximate_knn(doc_id, vec_to_search, planes_l, k=3, num_universes_to_use=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "df7aa8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest neighbors for document 0\n",
      "Document contents: #FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)\n",
      "\n",
      "Nearest neighbor at document id 2140\n",
      "document contents: @PopsRamjet come one, every now and then is not so bad :)\n",
      "Nearest neighbor at document id 701\n",
      "document contents: With the top cutie of Bohol :) https://t.co/Jh7F6U46UB\n",
      "Nearest neighbor at document id 51\n",
      "document contents: #FollowFriday @France_Espana @reglisse_menthe @CCI_inter for being top engaged members in my community this week :)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Nearest neighbors for document {doc_id}\")\n",
    "print(f\"Document contents: {doc_to_search}\")\n",
    "print(\"\")\n",
    "\n",
    "for neighbor_id in nearest_neighbor_ids:\n",
    "    print(f\"Nearest neighbor at document id {neighbor_id}\")\n",
    "    print(f\"document contents: {all_tweets[neighbor_id]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d87ec6",
   "metadata": {},
   "source": [
    "# 4 Conclusion\n",
    "Congratulations - Now you can look up vectors that are similar to the\n",
    "encoding of your tweet using LSH!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366bd260",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
